import streamlit as st
import whisper
import spacy
import os
import tempfile
from spacy import displacy

# ---- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–µ–π ----
@st.cache_resource
def load_models():
    whisper_model = whisper.load_model("medium")
    nlp = spacy.load("ru_core_news_sm")
    return whisper_model, nlp

# ---- –§—É–Ω–∫—Ü–∏–∏ –∞–Ω–∞–ª–∏–∑–∞ ----
def analyze_text(text, nlp):
    doc = nlp(text)
    results = {
        "promo_mentioned": False,
        "was_polite": False,
        "conflict_detected": False,
        "expired_products": False,
        "entities": [],
        "sentiment": "neutral"
    }

    promo_keywords = ["–∞–∫—Ü–∏–∏", "–∞–∫—Ü–∏—è", "—Å–∫–∏–¥–∫–∞", "–ø—Ä–æ–º–æ", "—Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"]
    polite_phrases = ["—Å–ø–∞—Å–∏–±–æ", "–ø–æ–∂–∞–ª—É–π—Å—Ç–∞", "–¥–æ–±—Ä—ã–π –¥–µ–Ω—å", "–±—É–¥–µ–º —Ä–∞–¥—ã –ø–æ–º–æ—á—å"]
    conflict_words = ["–æ—Å–∫–æ—Ä–±–ª–µ–Ω–∏–µ", "—Ö–∞–º—Å—Ç–≤–æ", "–ø—Ä–µ—Ç–µ–Ω–∑–∏—è", "–∂–∞–ª–æ–±–∞"]
    
    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ session_state
    results["promo_mentioned"] = any(token.text.lower() in promo_keywords for token in doc)
    results["was_polite"] = any(token.text.lower() in polite_phrases for token in doc)
    results["conflict_detected"] = any(token.text.lower() in conflict_words for token in doc)
    results["expired_products"] = any("—Å—Ä–æ–∫ –≥–æ–¥–Ω–æ—Å—Ç–∏" in sent.text for sent in doc.sents)
    results["entities"] = [(ent.text, ent.label_) for ent in doc.ents]
    
    if any(word in text.lower() for word in ["–ø—Ä–µ–∫—Ä–∞—Å–Ω–æ", "–æ—Ç–ª–∏—á–Ω–æ", "–¥–æ–≤–æ–ª–µ–Ω"]):
        results["sentiment"] = "positive"
    elif any(word in text.lower() for word in ["—É–∂–∞—Å–Ω–æ", "—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω", "–ø–ª–æ—Ö–æ"]):
        results["sentiment"] = "negative"
    
    return results

def main():
    st.title("üïµÔ∏è –ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–≤–µ—Ä–æ–∫ —Ç–∞–π–Ω–æ–≥–æ –ø–æ–∫—É–ø–∞—Ç–µ–ª—è")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if "raw_text" not in st.session_state:
        st.session_state.raw_text = ""
    if "edited_text" not in st.session_state:
        st.session_state.edited_text = ""

    # –ó–∞–≥—Ä—É–∑–∫–∞ –∞—É–¥–∏–æ
    audio_file = st.file_uploader("–í—ã–±–µ—Ä–∏—Ç–µ –∞—É–¥–∏–æ—Ñ–∞–π–ª", type=["mp3", "wav"])

    if audio_file and not st.session_state.raw_text:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
            tmp.write(audio_file.read())
            audio_path = tmp.name

        whisper_model, _ = load_models()
        with st.spinner("–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ..."):
            st.session_state.raw_text = whisper.transcribe(whisper_model, audio_path)["text"]
            st.session_state.edited_text = st.session_state.raw_text  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º edited_text
        
        os.unlink(audio_path)

    if st.session_state.raw_text:
        # –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ session_state
        st.subheader("‚úèÔ∏è –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏")
        st.session_state.edited_text = st.text_area(
            "–í–Ω–µ—Å–∏—Ç–µ –ø—Ä–∞–≤–∫–∏:", 
            value=st.session_state.edited_text,
            height=250,
            key="text_editor"  # –£–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –∏–∑–º–µ–Ω–µ–Ω–∏–π
        )

        # –ö–Ω–æ–ø–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        if st.button("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç"):
            _, nlp = load_models()
            analysis = analyze_text(st.session_state.edited_text, nlp)  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –û–¢–†–ï–î–ê–ö–¢–ò–†–û–í–ê–ù–ù–´–ô —Ç–µ–∫—Å—Ç
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞")
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            cols = st.columns(4)
            with cols[0]:
                st.metric("–£–ø–æ–º—è–Ω—É—Ç—ã –∞–∫—Ü–∏–∏", "‚úÖ" if analysis["promo_mentioned"] else "‚ùå")
            with cols[1]:
                st.metric("–í–µ–∂–ª–∏–≤–æ—Å—Ç—å", "‚úÖ" if analysis["was_polite"] else "‚ùå")
            with cols[2]:
                st.metric("–ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã", "‚ö†Ô∏è" if analysis["conflict_detected"] else "‚úÖ")
            with cols[3]:
                st.metric("–¢–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å", analysis["sentiment"].capitalize())

            # –°—É—â–Ω–æ—Å—Ç–∏
            st.subheader("üîç –û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ —Å—É—â–Ω–æ—Å—Ç–∏")
            if analysis["entities"]:
                for entity, label in analysis["entities"]:
                    st.markdown(f"- `{entity}` ({label})")
            else:
                st.info("–°—É—â–Ω–æ—Å—Ç–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã")

            # –î–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á–µ—Ç
            st.subheader("üìÑ –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–µ—Å—Ç–∞")
            if analysis["expired_products"]:
                st.error("**–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ:** –£–ø–æ–º–∏–Ω–∞–Ω–∏–µ –ø—Ä–æ—Å—Ä–æ—á–µ–Ω–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤")
            if analysis["conflict_detected"]:
                st.error("**–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ:** –ü—Ä–∏–∑–Ω–∞–∫–∏ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞")

            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è
            with st.expander("–°–∏–Ω—Ç–∞–∫—Å–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑"):
                doc = nlp(st.session_state.edited_text)
                html = displacy.render(doc, style="dep", page=True)
                st.components.v1.html(html, width=800, height=400, scrolling=True)

if __name__ == "__main__":
    main()